---
title: "PREDICTING BANK TELEMARKETING SUCCESS"
author: "Quang Duong"
date: "`r Sys.Date()`"
output:
    # pdf_document:
    #   highlight: pygments
    #   fig_width: 4
    #   fig_height: 3
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA, results = "hold", message = FALSE, warning = FALSE)
```
PREDICTING BANK TELEMARKETING SUCCESS

The success of marketing campaigns can be highly specific to the product, the target audience, and the campaign methods. In this problem, we examine data from direct marketing campaigns of a Portuguese banking institution between May 2008 and November 2010. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be or not subscribed.

In this analysis, the goal would be predicting the dependent variable y, which takes value 1 if the the client subscribed to a term deposit, and 0 otherwise. The data we will be using bank.csv is a subset of the original data, containing 5000 examples and 20 input variables. The variable information is as follows:

- *age*

- *job* - type of job

- *marital* - marital status

- *education* - Shows the level of education of each customer

- *default* - Whether a customer has credit in default

- *housing* - Does the customer have a housing loan?

- *loan* - Does the customer have a personal loan?

- *contact* - The contact communication type

- *month* - Last contact month of year

- *day_of_week* - Last contact day of Week

- *duration* - Last contact duration in seconds (Note: this variable is not known before making the call)

- *campaign* - Number of contact performed for the client during the campaign

- *pdays* - number of days that passed by after the client was last contacted from a previous campaign (value of 999 means the client was not previously contacted)

- *previous* - number of contacts performed before this campaign and for this client

- *poutcome* - outcome of the previous marketing campaign

- *emp.var.rate* - employment variation rate - quarterly indicator

- *cons.price.idx* - consumer price index - monthly indicator

- *cons.conf.idx* - consumer confidence index - monthly indicator

- *euribor3m* - euribor 3 month rate - daily indicator

- *nr.employed* - number of employees - quarterly indicator

## Problem 1 - Loading the Data
Use the read.csv function to load the contents of bank.csv into a data frame called bank. What is the average age in the data set?
```{r}
bank <- read.csv("bank.csv")
summary(bank)
```
## Problem 2 - Call Durations by Job
Build a boxplot that shows the call duration distributions over different jobs.
```{r}
library(ggplot2)
attach(bank)
ggplot() + geom_boxplot(data = bank, aes(job, duration)) + coord_flip()
sort(tapply(bank$duration, bank$job, mean))
```
## Problem 3 - Multicolinearity
As good practice, it is always helpful to first check for multicolinearity before running models, especially since this dataset contains macroeconomic indicators. Examine the correlation between the following variables: emp.var.rate, cons.price.idx, cons.conf.idx, euribor3m, and nr.employed.
```{r}
cor(bank[c("emp.var.rate","cons.price.idx","cons.conf.idx","euribor3m","nr.employed")])
```
## Problem 4 - Splitting into a Training and Testing Set
Obtain a random training/testing set split. Split months into a training data frame called "training" using the observations for which spl is TRUE and a testing data frame called "testing" using the observations for which spl is FALSE.
```{r}
library(caTools)
set.seed(201)
spl <- sample.split(bank$y, 0.7)
trainSet <- subset(bank, spl==TRUE)
testSet <- subset(bank, spl==FALSE)
```
## Problem 5 - Training a Logistic Regression Model
Train a logistic regression model using independent variables age, job, marital, education, default, housing, loan, contact, month, day_of_week, campaign, pdays, previous, poutcome, emp.var.rate, cons.price.idx, and cons.conf.idx, using the training set to obtain the model. Notice that we have removed duration (since it's not available before the call, so shouldn't be used in a strictly predictive model), euribor3m and nr.employed (due to multicolinearity issue).
```{r}
logReg <- glm(y ~ age + job + marital + education + default + housing + loan + contact + month + day_of_week + campaign + pdays + previous + poutcome + emp.var.rate + cons.conf.idx + cons.price.idx, data = trainSet, family = "binomial")
summary(logReg)
```
## Problem 6 - Interpreting Model Coefficients
What is the meaning of the coefficient labeled "monthmar" in the logistic regression summary output?

The coefficients of the model are the log odds associated with that variable; so we see that the odds of subscribing are exp(1.286)=3.618284 those of an otherwise identical contact. This means the contact is predicted to have 3.618284-1=2.618284 higher odds of subscribing.

## Problem 7 - Obtaining Test Set Predictions
Using your logistic regression model, obtain predictions on the test set. Then, using a probability threshold of 0.5, create a confusion matrix for the test set.

We would like to compare the predictions obtained by the logistic regression model and those obtained by a naive baseline model. Remember that the naive baseline model we use in this class always predicts the most frequent outcome in the training set for all observations in the test set.
```{r}
logPred <- predict(logReg, newdata = testSet, type = "response")
table(trainSet$y)
table(testSet$y)
table(testSet$y, logPred >= 0.5)
```
What is the number of test set observations where the prediction from the logistic regression model is different than the prediction from the baseline model?
```{r}
50+44
```
## Problem 8 - Computing Test-Set AUC
```{r}
library(ROCR)
logPredROCR <- prediction(logPred, labels = testSet$y)
ROC <- as.numeric(performance(logPredROCR, "auc")@y.values)
ROC
```
## Problem 9 - Interpreting AUC
The proportion of the time the model can differentiate between a randomly selected client who subscribed to a term deposit and a randomly selected client who did not subscribe correct

## Problem 10 - ROC Curves
```{r}
plot(performance(logPredROCR, "tpr", "fpr"))
```

Plot the colorized ROC curve for the logistic regression model's performance on the test set.
```{r}
plot(performance(logPredROCR, "tpr", "fpr"), colorize = TRUE, print.cutoffs.at=seq(0,1,0.1), text.adj=c(-0.7,1.2))
```

At roughly which logistic regression cutoff does the model achieve a true positive rate of 60% and a false positive rate of 25%?

From the colorized curve, we can see that the light turqoise color, corresponding to cutoff 0.11, is associated with a true positive rate of about 0.60 and false positive rate of about 0.25.

## Problem 12 - Cross-Validation to Select Parameters
Which of the following best describes how 10-fold cross-validation works when selecting between 4 different parameter values?

In 10-fold cross validation, the model with each parameter setting will be trained on ten 90% subsets of the training set. Hence, a total of 40 models will be trained. The models are evaluated in each case on the last 10% of the training set (not on the testing set).

## Problem 13 - Cross-Validation for a CART Model
Set the random seed to 201 (even though you have already done so earlier in the problem). Then use the caret package and the train function to perform 10-fold cross validation with the training data set to select the best cp value for a CART model that predicts the dependent variable y using the same set of independent variables as in the logistic regression (Problem 5). Select the cp value from a grid consisting of the 50 values 0.001, 0.002, ..., 0.05.

What cp value maximizes the cross-validation accuracy?
```{r}
library(caret)
library(rpart)
cpGrid <- expand.grid(cp = seq(0.001,0.05,0.001))
cpControl <- trainControl(method = "cv", number = 10)
set.seed(201)
train(y ~ age + job + marital + education + default + housing + loan + contact + month + day_of_week + campaign + pdays + previous + poutcome + emp.var.rate + cons.conf.idx + cons.price.idx, data = trainSet, method = "rpart", trControl = cpControl, tuneGrid = cpGrid)
```
## Problem 14 - Train CART Model
Build and plot the CART model trained with the parameter identified in Problem 13, again predicting the dependent variable using the same set of independent variables. What variable is used as the first (upper-most) split in the tree?
```{r}
library(rpart)
library(rpart.plot)
treeMod <- rpart(y ~ age + job + marital + education + default + housing + loan + contact + month + day_of_week + campaign + pdays + previous + poutcome + emp.var.rate + cons.conf.idx + cons.price.idx, data = trainSet, method = "class", control = rpart.control(cp = 0.009))
rpart.plot(treeMod)
```

## Problem 15 - Test-Set Accuracy for CART Model
Using the CART model you created in Problem 14, obtain predictions on the test set (using the parameter type="class" with the predict function). Then, create a confusion matrix for the test set.

What is the accuracy of your CART model?
```{r}
treePred <- predict(treeMod, newdata = testSet, type = "class")
table(testSet$y, treePred)
(1303+28)/(1303+28+20+149)
```
