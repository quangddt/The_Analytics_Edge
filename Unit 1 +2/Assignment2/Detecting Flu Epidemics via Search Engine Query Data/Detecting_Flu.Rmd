---
title: "Detecting Flu Epidemics via Search Engine Query Data"
author: "Quang Duong"
date: "`r Sys.Date()`"
output: 
    # pdf_document:
    #   highlight: pygments
  prettydoc::html_pretty:
    theme: architect
    highlight: github
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA)
```
Detecting Flu Epidemics via Search Engine Query Data 

Flu epidemics constitute a major public health concern causing respiratory illnesses, hospitalizations, and deaths. According to the National Vital Statistics Reports published in October 2012, influenza ranked as the eighth leading cause of death in 2011 in the United States. Each year, 250,000 to 500,000 deaths are attributed to influenza related diseases throughout the world.

The U.S. Centers for Disease Control and Prevention (CDC) and the European Influenza Surveillance Scheme (EISS) detect influenza activity through virologic and clinical data, including Influenza-like Illness (ILI) physician visits. Reporting national and regional data, however, are published with a 1-2 week lag.

The Google Flu Trends project was initiated to see if faster reporting can be made possible by considering flu-related online search queries -- data that is available almost immediately.

We would like to estimate influenza-like illness (ILI) activity using Google web search logs. Fortunately, one can easily access this data online:

ILI Data - The CDC publishes on its website the official regional and state-level percentage of patient visits to healthcare providers for ILI purposes on a weekly basis.

Google Search Queries - Google Trends allows public retrieval of weekly counts for every query searched by users around the world. For each location, the counts are normalized by dividing the count for each query in a particular week by the total number of online search queries submitted in that location during the week. Then, the values are adjusted to be between 0 and 1.

The csv file [FluTrain.csv](https://d37djvu3ytnwxt.cloudfront.net/assets/courseware/v1/df331a605387ca8382972c88d2853ddf/asset-v1:MITx+15.071x+2T2017+type@asset+block/FluTrain.csv) aggregates this data from January 1, 2004 until December 31, 2011 as follows:

"Week" - The range of dates represented by this observation, in year/month/day format.

"ILI" - This column lists the percentage of ILI-related physician visits for the corresponding week.

"Queries" - This column lists the fraction of queries that are ILI-related for the corresponding week, adjusted to be between 0 and 1 (higher values correspond to more ILI-related search queries).

Before applying analytics tools on the training set, we first need to understand the data at hand. Load "FluTrain.csv" into a data frame called FluTrain

```{r results='hold'}
FluTrain <- read.csv('FluTrain.csv')
str(FluTrain)
summary(FluTrain)
```
Before applying analytics tools on the training set, we first need to understand the data at hand. Load "FluTrain.csv" into a data frame called FluTrain. Looking at the time period 2004-2011, which week corresponds to the highest percentage of ILI-related physician visits?

```{r}
FluTrain$Week[which.max(FluTrain$ILI)]
```

Which week corresponds to the highest percentage of ILI-related query fraction?

```{r}
FluTrain$Week[which.max(FluTrain$Queries)]
```

Let us now understand the data at an aggregate level. Plot the histogram of the dependent variable, ILI. What best describes the distribution of values of ILI?

```{r warning=FALSE, error=FALSE}
library(ggplot2)
ggplot(FluTrain) + geom_histogram(aes(ILI), binwidth = 8/30)
```
We observe that most of the ILI values are small, with a relatively small number of much larger values (in statistics, this sort of data is called "skew right").

When handling a skewed dependent variable, it is often useful to predict the logarithm of the dependent variable instead of the dependent variable itself -- this prevents the small number of unusually large or small observations from having an undue influence on the sum of squared errors of predictive models. In this problem, we will predict the natural log of the ILI variable, which can be computed in R using the log() function.

Plot the natural logarithm of ILI versus Queries. What does the plot suggest?.

```{r}
ggplot(FluTrain) + geom_point(aes(Queries, log(ILI)))
```
There is a positive, linear relationship between log(ILI) and Queries.

Based on the plot we just made, it seems that a linear regression model could be a good modeling choice. Based on our understanding of the data from the previous subproblem, which model best describes our estimation problem?

log(ILI) = intercept + coefficient x Queries, where the coefficient is positive

Let's call the regression model above FluTrend1 and run it in R. Hint: to take the logarithm of a variable Var in a regression equation, you simply use log(Var) when specifying the formula to the lm() function.

What is the training set R-squared value for FluTrend1 model (the "Multiple R-squared")?

```{r}
FluTrend1 <- lm(log(ILI) ~ Queries, data = FluTrain)
summary(FluTrend1)
```
For a single variable linear regression model, there is a direct relationship between the R-squared and the correlation between the independent and the dependent variables. What is the relationship we infer from our problem? 

```{r results='hold'}
Correlation <- cor(log(FluTrain$ILI), FluTrain$Queries)
Correlation^2
log(1/Correlation)
exp(-0.5*Correlation)  
```
This suggest that R^2^ = Correlation^2^.

The csv file [FluTest.csv](https://d37djvu3ytnwxt.cloudfront.net/assets/courseware/v1/b09d1c001a63a540e853c5250f43d6a5/asset-v1:MITx+15.071x+2T2017+type@asset+block/FluTest.csv) provides the 2012 weekly data of the ILI-related search queries and the observed weekly percentage of ILI-related physician visits. Load this data into a data frame called FluTest.

Normally, we would obtain test-set predictions from the model FluTrend1 using the code

PredTest1 = predict(FluTrend1, newdata=FluTest)

However, the dependent variable in our model is log(ILI), so PredTest1 would contain predictions of the log(ILI) value. We are instead interested in obtaining predictions of the ILI value. We can convert from predictions of log(ILI) to predictions of ILI via exponentiation, or the exp() function. The new code, which predicts the ILI value, is

PredTest1 = exp(predict(FluTrend1, newdata=FluTest))

What is our estimate for the percentage of ILI-related physician visits for the week of March 11, 2012? (HINT: You can either just output FluTest$Week to find which element corresponds to March 11, 2012, or you can use the "which" function in R. To learn more about the which function, type ?which in your R console.)

```{r}
FluTest <- read.csv('FluTest.csv')
PredTest1 = exp(predict(FluTrend1, newdata = FluTest))
PredTest1[which(FluTest$Week=='2012-03-11 - 2012-03-17')]
```
What is the relative error betweeen the estimate (our prediction) and the observed value for the week of March 11, 2012? Note that the relative error is calculated as

(Observed ILI - Estimated ILI)/Observed ILI

```{r}
((FluTest$ILI-PredTest1)/FluTest$ILI)[11]
```
What is the Root Mean Square Error (RMSE) between our estimates and the actual observations for the percentage of ILI-related physician visits, on the test set?

```{r}
RMSE <- sqrt(sum((PredTest1-FluTest$ILI)^2)/nrow(FluTest))
RMSE
```
## Training a Time Series Model

The observations in this dataset are consecutive weekly measurements of the dependent and independent variables. This sort of dataset is called a "time series." Often, statistical models can be improved by predicting the current value of the dependent variable using the value of the dependent variable from earlier weeks. In our models, this means we will predict the ILI variable in the current week using values of the ILI variable from previous weeks.

First, we need to decide the amount of time to lag the observations. Because the ILI variable is reported with a 1- or 2-week lag, a decision maker cannot rely on the previous week's ILI value to predict the current week's value. Instead, the decision maker will only have data available from 2 or more weeks ago. We will build a variable called ILILag2 that contains the ILI value from 2 weeks before the current observation.

To do so, we will use the "zoo" package, which provides a number of helpful methods for time series models. While many functions are built into R, you need to add new packages to use some functions. New packages can be installed and loaded easily in R, and we will do this many times in this class. Run the following two commands to install and load the zoo package. In the first command, you will be prompted to select a CRAN mirror to use for your download. Select a mirror near you geographically.

```{r results='hide', message=FALSE}
library(zoo)
```
After installing and loading the zoo package, run the following commands to create the ILILag2 variable in the training set:

```{r}
ILILag2 = lag(zoo(FluTrain$ILI), -2, na.pad=TRUE)
FluTrain$ILILag2 = coredata(ILILag2)
summary(ILILag2)
```
There are 2 missing in the new variable ILILag2.

Plot the log of ILILag2 against the log of ILI. Which best describes the relationship between these two variables?

```{r warning=FALSE}
ggplot(FluTrain) + geom_point(aes(log(ILI), log(ILILag2)))
```
There is a strong positive relationship between log(ILILag2) and log(ILI).

Train a linear regression model on the FluTrain dataset to predict the log of the ILI variable using the Queries variable as well as the log of the ILILag2 variable. Call this model FluTrend2.

```{r}
FluTrend2 <- lm(log(ILI) ~ Queries + log(ILILag2), data = FluTrain)
summary(FluTrend2)
```
## Evaluating the Time Series Model in the Test Set

So far, we have only added the ILILag2 variable to the FluTrain data frame. To make predictions with our FluTrend2 model, we will also need to add ILILag2 to the FluTest data frame (note that adding variables before splitting into a training and testing set can prevent this duplication of effort).

Modify the code from the previous subproblem to add an ILILag2 variable to the FluTest data frame. How many missing values are there in this new variable?

```{r}
FluTest$ILILag2 <- lag(zoo(FluTest$ILI), -2, na.pad = TRUE)
summary(FluTest$ILILag2)
```
In this problem, the training and testing sets are split sequentially -- the training set contains all observations from 2004-2011 and the testing set contains all observations from 2012. There is no time gap between the two datasets, meaning the first observation in FluTest was recorded one week after the last observation in FluTrain. From this, we can identify how to fill in the missing values for the ILILag2 variable in FluTest.

```{r}
FluTest$ILILag2[1] = FluTrain$ILI[416]
FluTest$ILILag2[2] = FluTrain$ILI[417]
FluTest$ILILag2[1:2]
```
Obtain test set predictions of the ILI variable from the FluTrend2 model, again remembering to call the exp() function on the result of the predict() function to obtain predictions for ILI instead of log(ILI).

What is the test-set RMSE of the FluTrend2 model?

```{r}
PredTest2 <- exp(predict(FluTrend2, newdata = FluTest))
RMSE_2 <- sqrt(sum((PredTest2-FluTest$ILI)^2)/nrow(FluTest))
cat('RMSE = ',RMSE,'\nRMSE_2 = ',RMSE_2)
```
The FluTrend2 model, which predicts ILI from Queries and ILI of 2 weeks ago, results in a smaller test-set RMSE than FLuTrend1. Clearly, FluTrend2 is a superior model.

In this problem, we used a simple time series model with a single lag term. ARIMA models are a more general form of the model we built, which can include multiple lag terms as well as more complicated combinations of previous values of the dependent variable. If you're interested in learning more, check out ?arima or the available online tutorials for these sorts of models.






















